{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Sentences   Label  \\\n",
      "67    The floor is wet, there is blood on it, and it...  safety   \n",
      "143   The first thing I see is muddy teenage girls w...  safety   \n",
      "214   Be aware.....I will not be taking my nice dog ...  safety   \n",
      "263   Note about September 2018: the mosquitoes are ...  safety   \n",
      "285   Some stupid polish chick and her idiot boyfrie...  safety   \n",
      "347                         The apples looked diseased.  safety   \n",
      "351   The processing area was extremely clean and I ...  safety   \n",
      "411   On the way out, I stepped on some kind of dead...  safety   \n",
      "453   It's not OK if your dog gets startled in a sma...  safety   \n",
      "456   I liked this because I never really knew what ...  safety   \n",
      "470   When you are actually standing there in front ...  safety   \n",
      "589    This one is impeccably clean and well organized.  safety   \n",
      "592                  Wear old shoes because it's messy.  safety   \n",
      "773   They dont allow dogs which is mind blowing sin...  safety   \n",
      "801   There were no apples on the trees at all excep...  safety   \n",
      "912   Dirty shoes, strawberry stained hands and mild...  safety   \n",
      "1000  Something to note: I believe they do not allow...  safety   \n",
      "1234  There was mold spores growing on the pitas :*(...  safety   \n",
      "1273                                       It is messy.  safety   \n",
      "1277                      It's always such a messy job.  safety   \n",
      "1375  They also have a couple dogs and cats running ...  safety   \n",
      "1406   Before you know it, your allergies will be gone.  safety   \n",
      "\n",
      "                                 Words Notes  \n",
      "67    wet, blood, smells like, animals  None  \n",
      "143                 muddy, sheep, dogs  None  \n",
      "214                         aware, dog  None  \n",
      "263           note, mosquitoes, insane  None  \n",
      "285                                dog  None  \n",
      "347                           diseased  None  \n",
      "351                              clean  None  \n",
      "411                        dead rodent  None  \n",
      "453                         dog, crazy  None  \n",
      "456                              clean  None  \n",
      "470                            no pets  None  \n",
      "589       clean, organized, impeccably  None  \n",
      "592                              messy  None  \n",
      "773                        dogs, allow  None  \n",
      "801              bug, infested, rotten  None  \n",
      "912              dirty, stained, hands  None  \n",
      "1000         allow, dog, pets, walking  None  \n",
      "1234              mold spores growning  None  \n",
      "1273                             messy  None  \n",
      "1277                             messy  None  \n",
      "1375               dogs, cats, running  None  \n",
      "1406                         allergies  None  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot compute LDA over an empty collection (no terms)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8483c77b4149>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mcorpus_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbow_corpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mlda_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMulticore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         )\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_terms\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot compute LDA over an empty collection (no terms)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot compute LDA over an empty collection (no terms)"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from gensim import corpora, models\n",
    "\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return SnowballStemmer('english').stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "\n",
    "def score_doc(text, dictionary, lda_bow, lda_tfidf):\n",
    "    bow_vec = dictionary.doc2bow(preprocess(text))\n",
    "    for index, score in sorted(lda_bow[bow_vec], key=lambda tup: -1*tup[1]):\n",
    "        print(\"Score: {}\\t Topic: {}\".format(score, lda_bow.print_topic(index, 5)))\n",
    "        break\n",
    "\n",
    "    for index, score in sorted(lda_tfidf[bow_vec], key=lambda tup: -1*tup[1]):\n",
    "        print(\"Score: {}\\t Topic: {}\".format(score, lda_tfidf.print_topic(index, 5)))\n",
    "        break\n",
    "\n",
    "PATH=\"../data/yelp_labelling_1000.csv\"\n",
    "df=pd.read_csv(PATH)\n",
    "#print(df)\n",
    "df = df.fillna(\"None\")\n",
    "#print(df)\n",
    "df = df[df['Label'] != \"safety?\"]\n",
    "df.drop([\"Index\", \"Unnamed: 5\"], axis=1, inplace=True)\n",
    "text = df[df[\"Label\"] == \"safety\"]\n",
    "print(text)\n",
    "processed_docs = text['Sentences'].map(preprocess)\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} \\nWord: {}'.format(idx, topic))\n",
    "\n",
    "bow_stat=[]\n",
    "tfidf_stat=[]\n",
    "corpus_len=len(bow_corpus)\n",
    "for bow in bow_corpus:\n",
    "    for index, score in sorted(lda_model[bow], key=lambda tup: -1*tup[1]):\n",
    "        bow_stat.append(score)\n",
    "        #print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))\n",
    "        break\n",
    "\n",
    "    for index, score in sorted(lda_model_tfidf[bow], key=lambda tup: -1*tup[1]):\n",
    "        tfidf_stat.append(score)\n",
    "        #print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))\n",
    "        break\n",
    "\n",
    "# bow_stat.sort()\n",
    "# tfidf_stat.sort()\n",
    "\n",
    "# print(f\"Median Score using BOG model {bow_stat[corpus_len // 2]}\")\n",
    "# print(f\"Median Score using TFIDF model{tfidf_stat[corpus_len // 2]}\")\n",
    "\n",
    "# print(f\"Average Score using BOG model {sum(bow_stat)/corpus_len}\")\n",
    "# print(f\"Average Score using TFIDF model{sum(tfidf_stat)/corpus_len}\")\n",
    "\n",
    "# text=\"Before you know it, your allergies will be gone.\"\n",
    "# score_doc(text, dictionary, lda_model, lda_model_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
